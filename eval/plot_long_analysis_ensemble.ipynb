{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routines for plotting the long-term performance (e.g., temporal mean bias/variance, zonal means/eofs) of the emulator, averaged across different randomly initialized and trained emulators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import yaml\n",
    "from analysis.io_utils import load_params\n",
    "from analysis.plot_config import params, contourLevels, colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all ensemble run_nums\n",
    "run_nums = ['MAE_mr0.5_seed_0_2phase_nf4_ft_dropPEPR', 'MAE_mr0.5_seed_10_2phase_nf4_ft_dropPEPR',\n",
    "            'MAE_mr0.5_seed_20_2phase_nf4_ft_dropPEPR', 'MAE_mr0.5_seed_30_2phase_nf4_ft_dropPEPR',\n",
    "           'MAE_mr0.5_seed_40_2phase_nf4_ft_dropPEPR']\n",
    "#run_nums = ['BASE_seed_0_2phase_1000epochs','BASE_seed_10_2phase_1000epochs', \n",
    "#            'BASE_seed_20_2phase_1000epochs', 'BASE_seed_30_2phase_1000epochs', \n",
    "#            'BASE_seed_40_2phase_1000epochs']\n",
    "\n",
    "# Config file path\n",
    "config_file_path = \"config/config_MAE_mr0.5_seed_0_2phase_nf4_ft_dropPEPR.yaml\"\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dataset_params = config[\"dataset_params\"]\n",
    "short_analysis_params = config[\"short_analysis_params\"]\n",
    "long_analysis_params = config[\"long_analysis_params\"]\n",
    "\n",
    "root_dir = dataset_params[\"root_dir\"]\n",
    "\n",
    "params_filename = dataset_params[\"params_filename\"]\n",
    "\n",
    "params_fp = os.path.join(root_dir, run_nums[0], params_filename) \n",
    "train_params = load_params(params_fp) # Read in params file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather training statistics\n",
    "\n",
    "analysis_dir = os.path.join(root_dir, run_nums[0], \"analysis\", \"train\")\n",
    "\n",
    "data = np.load(analysis_dir + '/temporal_mean.npz')\n",
    "u_mean_train = data['U_sample_mean']\n",
    "v_mean_train = data['V_sample_mean']\n",
    "omega_mean_train = data['Omega_sample_mean']\n",
    "\n",
    "data = np.load(analysis_dir + '/zonal_mean.npz')\n",
    "u_zonal_mean_train = data['U_zonal_mean']\n",
    "omega_zonal_mean_train = data['Omega_zonal_mean']\n",
    "\n",
    "data = np.load(analysis_dir + '/zonal_eof_pc.npz')\n",
    "u_eofs_train = data['U_eofs']\n",
    "u_expvar_train = data['U_expvar']\n",
    "omega_eofs_train = data['Omega_eofs']\n",
    "omega_expvar_train = data['Omega_expvar']\n",
    "\n",
    "data = np.load(analysis_dir + \"/zonal_eof_pc.npz\", allow_pickle=True)\n",
    "PC_acf_u_train = data[\"U_pc_acf\"]\n",
    "PC_acf_omega_train = data[\"Omega_pc_acf\"]\n",
    "\n",
    "data = np.load(analysis_dir + '/extremes.npz')\n",
    "u_std = 2.34\n",
    "v_std = 1.88\n",
    "omega_std = 10.41\n",
    "u_max_train = np.asarray(data['U_max_arr'][::3]/u_std)\n",
    "u_min_train = np.asarray(data['U_min_arr'][::3]/u_std)\n",
    "v_max_train = np.asarray(data['V_max_arr'][::3]/v_std)\n",
    "v_min_train = np.asarray(data['V_min_arr'][::3]/v_std)\n",
    "omega_max_train = np.asarray(data['Omega_max_arr'][::3]/omega_std)\n",
    "omega_min_train = np.asarray(data['Omega_min_arr'][::3]/omega_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather ground truth statistics\n",
    "\n",
    "analysis_dir = os.path.join(root_dir, run_nums[0], \"analysis\", \"truth\")\n",
    "\n",
    "data = np.load(analysis_dir + '/temporal_mean.npz')\n",
    "u_mean_truth = data['U_sample_mean']\n",
    "v_mean_truth = data['V_sample_mean']\n",
    "omega_mean_truth = data['Omega_sample_mean']\n",
    "\n",
    "data = np.load(analysis_dir + '/zonal_mean.npz')\n",
    "u_zonal_mean_truth = data['U_zonal_mean']\n",
    "omega_zonal_mean_truth = data['Omega_zonal_mean']\n",
    "\n",
    "data = np.load(analysis_dir + '/zonal_eof_pc.npz')\n",
    "u_eofs_truth = data['U_eofs']\n",
    "u_expvar_truth = data['U_expvar']\n",
    "omega_eofs_truth = data['Omega_eofs']\n",
    "omega_expvar_truth = data['Omega_expvar']\n",
    "\n",
    "data = np.load(analysis_dir + \"/zonal_eof_pc.npz\", allow_pickle=True)\n",
    "PC_acf_u_truth = data[\"U_pc_acf\"]\n",
    "PC_acf_omega_truth = data[\"Omega_pc_acf\"]\n",
    "\n",
    "div_truth = np.load(analysis_dir + '/div.npy')\n",
    "\n",
    "data = np.load(analysis_dir + '/extremes.npz')\n",
    "u_std = 2.34\n",
    "v_std = 1.88\n",
    "omega_std = 10.41\n",
    "u_max_truth = np.asarray(data['U_max_arr'][::3]/u_std)\n",
    "u_min_truth = np.asarray(data['U_min_arr'][::3]/u_std)\n",
    "v_max_truth = np.asarray(data['V_max_arr'][::3]/v_std)\n",
    "v_min_truth = np.asarray(data['V_min_arr'][::3]/v_std)\n",
    "omega_max_truth = np.asarray(data['Omega_max_arr'][::3]/omega_std)\n",
    "omega_min_truth = np.asarray(data['Omega_min_arr'][::3]/omega_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all emulator statistics\n",
    "\n",
    "u_mean, v_mean, omega_mean = [], [], []\n",
    "u_zonal_mean, omega_zonal_mean = [], []\n",
    "u_eofs, omega_eofs = [], []\n",
    "u_expvar, omega_expvar = [], []\n",
    "PC_acf_u, PC_acf_omega = [], []\n",
    "div = []\n",
    "u_max, v_max, omega_max = [], [], []\n",
    "u_min, v_min, omega_min = [], [], []\n",
    "u_std = 2.34\n",
    "v_std = 1.88\n",
    "omega_std = 10.41\n",
    "\n",
    "for run_num in run_nums:\n",
    "    analysis_dir = os.path.join(root_dir, run_num, \"analysis\", \"emulate\")\n",
    "\n",
    "    # Temporal means\n",
    "    data = np.load(analysis_dir + '/temporal_mean.npz')\n",
    "    print(f'u_mean.shape: {data[\"U_sample_mean\"].shape}')\n",
    "    u_mean.append(data['U_sample_mean'])\n",
    "    v_mean.append(data['V_sample_mean'])\n",
    "    omega_mean.append(data['Omega_sample_mean'])\n",
    "\n",
    "    # Zonal means\n",
    "    data = np.load(analysis_dir + '/zonal_mean.npz')\n",
    "    print(f'u_zonal_mean.shape: {data[\"U_zonal_mean\"].shape}')\n",
    "    u_zonal_mean.append(data['U_zonal_mean'])\n",
    "    omega_zonal_mean.append(data['Omega_zonal_mean'])\n",
    "\n",
    "    # EOFs\n",
    "    data = np.load(analysis_dir + '/zonal_eof_pc.npz')\n",
    "    print(f'u_eof.shape: {data[\"U_eofs\"].shape}')\n",
    "    u_eofs.append(data['U_eofs'])\n",
    "    u_expvar.append(data['U_expvar'])\n",
    "    omega_eofs.append(data['Omega_eofs'])\n",
    "    omega_expvar.append(data['Omega_expvar'])\n",
    "    \n",
    "    # PC Autocorrelation\n",
    "    data = np.load(analysis_dir + \"/zonal_eof_pc.npz\", allow_pickle=True)\n",
    "    PC_acf_u.append(data[\"U_pc_acf\"])\n",
    "    PC_acf_omega.append(data[\"Omega_pc_acf\"])\n",
    "\n",
    "    # Div\n",
    "    data = np.load(analysis_dir + '/div.npy')\n",
    "    print(f'div.shape: {data.shape}')\n",
    "    div.append(data)\n",
    "\n",
    "    # Extremes\n",
    "    data = np.load(analysis_dir + '/extremes.npz')\n",
    "    print(f'u_max.shape: {data[\"U_max_arr\"].shape}')\n",
    "    u_max.append(data['U_max_arr']/u_std)\n",
    "    u_min.append(data['U_min_arr']/u_std)\n",
    "    v_max.append(data['V_max_arr']/v_std)\n",
    "    v_min.append(data['V_min_arr']/v_std)\n",
    "    omega_max.append(data['Omega_max_arr']/omega_std)\n",
    "    omega_min.append(data['Omega_min_arr']/omega_std)\n",
    "    \n",
    "\n",
    "u_max = np.array(u_max)\n",
    "u_min = np.array(u_min)\n",
    "v_max = np.array(v_max)\n",
    "v_min = np.array(v_min)\n",
    "omega_max = np.array(omega_max)\n",
    "omega_min = np.array(omega_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Means: Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average (over ensemble) absolute bias for U, V, Omega temporal means:\n",
    "#   mean(abs(truth - train))\n",
    "#   mean_i(abs(truth - pred_i))\n",
    "#   mean_i(abs(train - pred_i))\n",
    "\n",
    "def reduce(x, reduce_type):\n",
    "    if reduce_type == \"abs\":\n",
    "        return np.abs(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "reduce_type = \"abs\"\n",
    "\n",
    "u_temporal_bias = []\n",
    "v_temporal_bias = []\n",
    "omega_temporal_bias = []\n",
    "\n",
    "# Truth vs train\n",
    "u_temporal_bias.append(reduce(u_mean_truth - u_mean_train, reduce_type))\n",
    "v_temporal_bias.append(reduce(v_mean_truth - v_mean_train, reduce_type))\n",
    "omega_temporal_bias.append(reduce(omega_mean_truth - omega_mean_train, reduce_type))\n",
    "\n",
    "# Truth vs pred\n",
    "u_abs_err, v_abs_err, omega_abs_err = [], [], []\n",
    "for i in range(len(u_mean)):\n",
    "    u_abs_err.append(reduce(u_mean_truth - u_mean[i], reduce_type))\n",
    "    v_abs_err.append(reduce(v_mean_truth - v_mean[i], reduce_type))\n",
    "    omega_abs_err.append(reduce(omega_mean_truth - omega_mean[i], reduce_type))\n",
    "\n",
    "u_abs_err = np.mean(u_abs_err, axis=0)\n",
    "v_abs_err = np.mean(v_abs_err, axis=0)\n",
    "omega_abs_err = np.mean(omega_abs_err, axis=0)\n",
    "print(f'u_abs_err.shape: {u_abs_err.shape}')\n",
    "\n",
    "u_temporal_bias.append(u_abs_err)\n",
    "v_temporal_bias.append(v_abs_err)\n",
    "omega_temporal_bias.append(omega_abs_err)\n",
    "\n",
    "# Train vs pred\n",
    "u_abs_err, v_abs_err, omega_abs_err = [], [], []\n",
    "for i in range(len(u_mean)):\n",
    "    u_abs_err.append(reduce(u_mean_train - u_mean[i], reduce_type))\n",
    "    v_abs_err.append(reduce(v_mean_train - v_mean[i], reduce_type))\n",
    "    omega_abs_err.append(reduce(omega_mean_train - omega_mean[i], reduce_type))\n",
    "\n",
    "u_abs_err = np.mean(u_abs_err, axis=0)\n",
    "v_abs_err = np.mean(v_abs_err, axis=0)\n",
    "omega_abs_err = np.mean(omega_abs_err, axis=0)\n",
    "print(f'u_abs_err.shape: {u_abs_err.shape}')\n",
    "\n",
    "u_temporal_bias.append(u_abs_err)\n",
    "v_temporal_bias.append(v_abs_err)\n",
    "omega_temporal_bias.append(omega_abs_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3), sharex=True, sharey=True)\n",
    "\n",
    "titles_1 = ['U', 'V', 'Omega']\n",
    "titles_2 = ['Truth vs Train', 'Truth vs ML', 'Train vs ML']\n",
    "contourlevels = 100\n",
    "vmax = [2, 0.5, 5]\n",
    "vmin = [0, -0.5, -5]\n",
    "\n",
    "plotting_vars = [u_temporal_bias, v_temporal_bias, omega_temporal_bias]\n",
    "\n",
    "for i in range(1):\n",
    "    for j in range(3):\n",
    "        norm = Normalize(vmin=vmin[i], vmax=vmax[i])\n",
    "        im = axes[j].contourf(plotting_vars[i][j], \n",
    "                                levels=contourlevels, \n",
    "                                cmap='bwr', \n",
    "                                norm=norm)\n",
    "        axes[j].set_title(f\"{titles_1[i]}: {titles_2[j]}\")\n",
    "\n",
    "        # Set ticks only on edge subplots\n",
    "        #if i == 2:\n",
    "        axes[j].set_xticks([0, 256//2, 256])\n",
    "        axes[j].set_xticklabels(['0', 'π', '2π'])\n",
    "        #else:\n",
    "        #    axes[j].set_xticks([])\n",
    "        \n",
    "        if j == 0:\n",
    "            axes[j].set_yticks([0, 256//2, 256])\n",
    "            axes[j].set_yticklabels(['0', 'π', '2π'])\n",
    "        else:\n",
    "            axes[j].set_yticks([])\n",
    "\n",
    "    # Add one colorbar per row\n",
    "    sm = mpl.cm.ScalarMappable(norm=norm, cmap='bwr')\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=axes[:], orientation='vertical', shrink=0.8)\n",
    "    cbar.set_label(f\"{titles_1[i]} bias\")\n",
    "\n",
    "# Shared labels\n",
    "fig.text(0.5, 0.04, 'x', ha='center', fontsize=14)\n",
    "fig.text(0.06, 0.5, 'y', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# Set aspect ratio to equal and remove labels for all axes\n",
    "for ax in axes.flat:\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Means: Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variance (over ensemble) of the temporal bias for U, V, Omega temporal means:\n",
    "#   var_i(truth - pred_i)\n",
    "#   var_i(train - pred_i)\n",
    "\n",
    "def reduce(x, reduce_type):\n",
    "    if reduce_type == \"abs\":\n",
    "        return np.abs(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "reduce_type = None\n",
    "\n",
    "u_temporal_var = []\n",
    "v_temporal_var = []\n",
    "omega_temporal_var = []\n",
    "\n",
    "# Truth vs pred\n",
    "u_abs_err, v_abs_err, omega_abs_err = [], [], []\n",
    "for i in range(len(u_mean)):\n",
    "    u_abs_err.append(reduce(u_mean_truth - u_mean[i], reduce_type))\n",
    "    v_abs_err.append(reduce(v_mean_truth - v_mean[i], reduce_type))\n",
    "    omega_abs_err.append(reduce(omega_mean_truth - omega_mean[i], reduce_type))\n",
    "\n",
    "u_var = np.var(u_abs_err, axis=0)\n",
    "v_var = np.var(v_abs_err, axis=0)\n",
    "omega_var = np.var(omega_abs_err, axis=0)\n",
    "print(f'u_var.shape: {u_var.shape}')\n",
    "\n",
    "u_temporal_var.append(u_var)\n",
    "v_temporal_var.append(v_var)\n",
    "omega_temporal_var.append(omega_var)\n",
    "\n",
    "# Train vs pred\n",
    "u_abs_err, v_abs_err, omega_abs_err = [], [], []\n",
    "for i in range(len(u_mean)):\n",
    "    u_abs_err.append(reduce(u_mean_train - u_mean[i], reduce_type))\n",
    "    v_abs_err.append(reduce(v_mean_train - v_mean[i], reduce_type))\n",
    "    omega_abs_err.append(reduce(omega_mean_train - omega_mean[i], reduce_type))\n",
    "\n",
    "u_var = np.var(u_abs_err, axis=0)\n",
    "v_var = np.var(v_abs_err, axis=0)\n",
    "omega_var = np.var(omega_abs_err, axis=0)\n",
    "print(f'u_var.shape: {u_var.shape}')\n",
    "\n",
    "u_temporal_var.append(u_var)\n",
    "v_temporal_var.append(v_var)\n",
    "omega_temporal_var.append(omega_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variance (over ensemble) bias of U, V, Omega temporal means\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(6, 9))\n",
    "titles_1 = ['U', 'V', 'Omega']\n",
    "titles_2 = ['Truth vs ML', 'Train vs ML']\n",
    "contourlevels = 100\n",
    "vmax = [2, 0.5, 5]\n",
    "vmin = [0, 0, 0]\n",
    "\n",
    "plotting_vars = np.sqrt([u_temporal_var, v_temporal_var, omega_temporal_var])\n",
    "for i in range(3):\n",
    "    for j in range(2):\n",
    "        im = axes[i, j].contourf(plotting_vars[i][j], \n",
    "                                 levels=contourlevels, \n",
    "                                 cmap='bwr', \n",
    "                                 vmax=vmax[i], \n",
    "                                 vmin=vmin[i])\n",
    "        axes[i, j].set_title(titles_1[i] + ': ' +titles_2[j])\n",
    "\n",
    "    #cb = fig.colorbar(im, ax=axes[i, :], orientation='horizontal', shrink=0.5)\n",
    "\n",
    "# Set aspect ratio to equal and remove labels for all axes\n",
    "for ax in axes.flat:\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zonal Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot zonal mean statistics across ensemble\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "u_zonal_mean_mean = np.mean(u_zonal_mean, axis=0)\n",
    "u_zonal_mean_std = np.std(u_zonal_mean, axis=0)\n",
    "print(f'u_zonal_mean_mean.shape: {u_zonal_mean_mean.shape}')\n",
    "\n",
    "omega_zonal_mean_mean = np.mean(omega_zonal_mean, axis=0)\n",
    "omega_zonal_mean_std = np.std(omega_zonal_mean, axis=0)\n",
    "print(f'omega_zonal_mean_mean.shape: {omega_zonal_mean_mean.shape}')\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(4, 4),\n",
    "                         sharey=True)\n",
    "\n",
    "y = np.linspace(0, 2*np.pi, u_zonal_mean_mean.shape[0])\n",
    "\n",
    "axes.plot(u_zonal_mean_truth, y, '-k', label='Truth')\n",
    "axes.plot(u_zonal_mean_train, y, '-r', label='Train')\n",
    "axes.plot(u_zonal_mean_mean, y, '-b', label='Emulator')\n",
    "axes.fill_betweenx(y, u_zonal_mean_mean - u_zonal_mean_std, u_zonal_mean_mean + u_zonal_mean_std, alpha=0.1, color='b')\n",
    "axes.set_ylabel('y')\n",
    "\n",
    "#axes[1].plot(omega_zonal_mean_truth, y, '-k', label='Truth')\n",
    "#axes[1].plot(omega_zonal_mean_train, y, '-r', label='Train')\n",
    "#axes[1].plot(omega_zonal_mean_mean, y, '-b', label='Emulator')\n",
    "#axes[1].fill_betweenx(y, omega_zonal_mean_mean - omega_zonal_mean_std, omega_zonal_mean_mean + omega_zonal_mean_std, alpha=0.25, color='b')\n",
    "\n",
    "axes.set_title(f'U zonal mean')\n",
    "#axes[1].set_title(f'$\\omega$ zonal mean')\n",
    "\n",
    "#axes.legend(frameon=False, fontsize='x-small', loc='lower right')\n",
    "# plt.tight_layout()\n",
    "# axes[1].legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF: U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot zonal EOF of U statistics across ensemble\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "u_eofs_mean, u_eofs_std = [], []\n",
    "neofs = 2\n",
    "\n",
    "for i in range(neofs):\n",
    "    u_eofs_mean.append(np.mean([u_eofs[j][:, i] for j in range(len(u_eofs))], axis=0))\n",
    "    u_eofs_std.append(np.std([u_eofs[j][:, i] for j in range(len(u_eofs))], axis=0))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "y = np.linspace(0, 2*np.pi, u_eofs_train.shape[0])\n",
    "titles = [rf'$u$ EOF 1', rf'$u$ EOF 2']\n",
    "\n",
    "axs = axes.flatten()\n",
    "for i in range(neofs):\n",
    "    ueof_truth = u_eofs_truth[:, i]\n",
    "    ueof_train = u_eofs_train[:, i]\n",
    "    if i == 1:\n",
    "        ueof_train *= -1\n",
    "    axs[i].plot(ueof_truth, y, '-k', label='Truth')\n",
    "    axs[i].plot(ueof_train, y, '-r', label='Train')\n",
    "    #axs[i].plot(u_eofs_mean[i], y, '-b', label='ML')\n",
    "    #axs[i].fill_betweenx(y, u_eofs_mean[i] - u_eofs_std[i], u_eofs_mean[i] + u_eofs_std[i],\n",
    "    #                     color='b', alpha=0.1)\n",
    "    axs[i].set_title(titles[i])\n",
    "    \n",
    "for i in range(5):\n",
    "    ueof1 = u_eofs[i][:, 0]\n",
    "    if i in [2,4]:\n",
    "        ueof1 = -1 * u_eofs[i][:, 0]\n",
    "    axs[0].plot(ueof1, y, linewidth=0.5)\n",
    "for i in range(5):\n",
    "    ueof2 = u_eofs[i][:, 1]\n",
    "    if i in [3]:\n",
    "        ueof2 = -1 * u_eofs[i][:, 1]\n",
    "    axs[1].plot(ueof2, y, linewidth=0.5)\n",
    "\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF: Omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot zonal EOF of Omega statistics across ensemble\n",
    "\n",
    "omega_eofs_mean, omega_eofs_std = [], []\n",
    "neofs = 2\n",
    "\n",
    "for i in range(neofs):\n",
    "    omega_eofs_mean.append(np.mean([omega_eofs[j][:, i] for j in range(len(omega_eofs))], axis=0))\n",
    "    omega_eofs_std.append(np.std([omega_eofs[j][:, i] for j in range(len(omega_eofs))], axis=0))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "y = np.linspace(0, 2*np.pi, omega_eofs_train.shape[0])\n",
    "\n",
    "axs = axes.flatten()\n",
    "for i in range(neofs):\n",
    "    axs[i].plot(omega_eofs_truth[i, :], y, '-k', label='Truth')\n",
    "    axs[i].plot(omega_eofs_train[:, i], y, '-r', label='Train')\n",
    "    axs[i].plot(omega_eofs_mean[i], y, '-b', label='ML')\n",
    "    axs[i].fill_betweenx(y, omega_eofs_mean[i] - omega_eofs_std[i], omega_eofs_mean[i] + omega_eofs_std[i],\n",
    "                         color='b', alpha=0.1)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC Auto Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [r\"Truth\", r\"Train\", r\"Emulator\"]\n",
    "colors = ['-k', '--r', '-.b']\n",
    "color=['k', 'r', 'b']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8), layout='constrained',\n",
    "                         sharex=True, sharey=True)\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "datasets = [('truth', PC_acf_u_truth, PC_acf_omega_truth),\n",
    "            ('train', PC_acf_u_train, PC_acf_omega_train),\n",
    "            ('emulator', PC_acf_u, PC_acf_omega)]\n",
    "\n",
    "for i, j in enumerate(datasets):\n",
    "\n",
    "    curve_id, acf_u, acf_omega = j\n",
    "\n",
    "    for count in range(2):\n",
    "\n",
    "        if curve_id == 'emulator':\n",
    "            # Compute emulator statistics\n",
    "            acf_u_median = np.median([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], axis=0)\n",
    "            acf_u_ub = np.quantile([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], 0.75, axis=0)\n",
    "            acf_u_lb = np.quantile([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], 0.25, axis=0)\n",
    "\n",
    "            acf_omega_median = np.median([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], axis=0)\n",
    "            acf_omega_ub = np.quantile([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], 0.75, axis=0)\n",
    "            acf_omega_lb = np.quantile([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], 0.25, axis=0)\n",
    "        else:\n",
    "            acf_u_median = acf_u[count]['acf']\n",
    "            acf_u_ub = acf_u[count]['confint'][:,0]\n",
    "            acf_u_lb = acf_u[count]['confint'][:,1]\n",
    "\n",
    "            acf_omega_median = acf_omega[count]['acf']\n",
    "            acf_omega_ub = acf_omega[count]['confint'][:,0]\n",
    "            acf_omega_lb = acf_omega[count]['confint'][:,1]\n",
    "\n",
    "        # Training data and emulation data are saved at different time steps\n",
    "        if curve_id == 'emulator':\n",
    "            time = np.linspace(0, acf_u_median.shape[0], acf_u_median.shape[0])\n",
    "        else:\n",
    "            time = np.linspace(0, acf_u_median.shape[0]/train_params[\"target_step\"], acf_u_median.shape[0])\n",
    "\n",
    "        axes[0,count].plot(time, acf_u_median, colors[i], label=label[i])\n",
    "        axes[0,count].fill_between(time, acf_u_lb, acf_u_ub, color=color[i], alpha=0.2)\n",
    "\n",
    "        axes[1,count].plot(time, acf_omega_median, colors[i], label=label[i])\n",
    "        axes[1,count].fill_between(time, acf_omega_lb, acf_omega_ub, color=color[i], alpha=0.2)\n",
    "        \n",
    "        axes[0,count].set_title(rf'$u$ PC{count+1} AutoCorr')\n",
    "        axes[1,count].set_title(rf'$\\omega$ PC{count+1} AutoCorr')\n",
    "\n",
    "axes[0,0].legend(frameon=False)\n",
    "#axes[1,0].legend(frameon=False)\n",
    "axes[1,0].set_xlabel('$\\Delta t$')\n",
    "axes[1,1].set_xlabel('$\\Delta t$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [r\"Truth\", r\"Train\", r\"Emulator\"]\n",
    "colors = ['-k', '--r', '-.b']\n",
    "color=['k', 'r', 'b']\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(4, 4), layout='constrained',\n",
    "                         sharex=True, sharey=True)\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "datasets = [('truth', PC_acf_u_truth),\n",
    "            ('train', PC_acf_u_train),\n",
    "            ('emulator', PC_acf_u)]\n",
    "\n",
    "for i, j in enumerate(datasets):\n",
    "\n",
    "    curve_id, acf_u = j\n",
    "\n",
    "    for count in range(1, 2):\n",
    "\n",
    "        if curve_id == 'emulator':\n",
    "            # Compute emulator statistics\n",
    "            acf_u_median = np.median([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], axis=0)\n",
    "            acf_u_ub = np.quantile([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], 0.75, axis=0)\n",
    "            acf_u_lb = np.quantile([PC_acf_u[k][count]['acf'] for k in range(len(run_nums))], 0.25, axis=0)\n",
    "\n",
    "            #acf_omega_median = np.median([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], axis=0)\n",
    "            #acf_omega_ub = np.quantile([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], 0.75, axis=0)\n",
    "            #acf_omega_lb = np.quantile([PC_acf_omega[k][count]['acf'] for k in range(len(run_nums))], 0.25, axis=0)\n",
    "        else:\n",
    "            acf_u_median = acf_u[count]['acf']\n",
    "            acf_u_ub = acf_u[count]['confint'][:,0]\n",
    "            acf_u_lb = acf_u[count]['confint'][:,1]\n",
    "\n",
    "            #acf_omega_median = acf_omega[count]['acf']\n",
    "            #acf_omega_ub = acf_omega[count]['confint'][:,0]\n",
    "            #acf_omega_lb = acf_omega[count]['confint'][:,1]\n",
    "\n",
    "        # Training data and emulation data are saved at different time steps\n",
    "        if curve_id == 'emulator':\n",
    "            time = np.linspace(0, acf_u_median.shape[0], acf_u_median.shape[0])\n",
    "        else:\n",
    "            time = np.linspace(0, acf_u_median.shape[0]/train_params[\"target_step\"], acf_u_median.shape[0])\n",
    "\n",
    "        axes.plot(time, acf_u_median, colors[i], label=label[i])\n",
    "        axes.fill_between(time, acf_u_lb, acf_u_ub, color=color[i], alpha=0.2)\n",
    "\n",
    "        #axes[1,count].plot(time, acf_omega_median, colors[i], label=label[i])\n",
    "        #axes[1,count].fill_between(time, acf_omega_lb, acf_omega_ub, color=color[i], alpha=0.2)\n",
    "        \n",
    "        axes.set_title(rf'$u$ EOF {count+1} AutoCorr')\n",
    "        #axes[1,count].set_title(rf'$\\omega$ PC{count+1} AutoCorr')\n",
    "\n",
    "        axes.set_xlabel('$\\Delta t$')\n",
    "\n",
    "axes.legend(frameon=False)\n",
    "axes.set_ylim([0, 1])\n",
    "axes.set_xlim([0, 300])\n",
    "#axes[1,0].legend(frameon=False)\n",
    "#axes[1,0].set_xlabel('$\\Delta t$')\n",
    "#axes[1,1].set_xlabel('$\\Delta t$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [r\"Truth\", r\"Train\", r\"Emulator\"]\n",
    "colors = ['-k', '--r', '-.b']\n",
    "color=['k', 'r', 'b']\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(8, 4),\n",
    "                         ncols=2, nrows=1,\n",
    "                         layout='constrained',\n",
    "                         sharex=True, sharey=True)\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "datasets = [('truth', PC_acf_u_truth),\n",
    "            ('train', PC_acf_u_train),\n",
    "            ('emulator', PC_acf_u)]\n",
    "\n",
    "for i, j in enumerate(datasets):\n",
    "\n",
    "    curve_id, acf_u = j\n",
    "\n",
    "    for count in range(2):\n",
    "\n",
    "        if curve_id == 'emulator':\n",
    "            for k in range(len(run_nums)):\n",
    "                time = np.linspace(0, acf_u[k][count]['acf'].shape[0], acf_u[k][count]['acf'].shape[0])\n",
    "                axes[count].plot(time, acf_u[k][count]['acf'], linewidth=0.5)\n",
    "\n",
    "        else:\n",
    "            acf_u_median = acf_u[count]['acf']\n",
    "            acf_u_ub = acf_u[count]['confint'][:,0]\n",
    "            acf_u_lb = acf_u[count]['confint'][:,1]\n",
    "            time = np.linspace(0, acf_u_median.shape[0]/train_params[\"target_step\"], acf_u_median.shape[0])\n",
    "            axes[count].plot(time, acf_u_median, colors[i]) #, label=label[i])\n",
    "            axes[count].fill_between(time, acf_u_lb, acf_u_ub, color=color[i], alpha=0.2)\n",
    "\n",
    "        \n",
    "        axes[count].set_title(rf'$u$ EOF {count+1} AutoCorr')\n",
    "\n",
    "        axes[count].set_xlabel('$\\Delta t$')\n",
    "\n",
    "        axes[count].set_ylim([0, 1])\n",
    "        axes[count].set_xlim([0, 300])\n",
    "\n",
    "axes[1].legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and plot statistics (across emulators) of divergence of flow\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "div_mean = np.mean(div, axis=0)\n",
    "div_std = np.std(div, axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, figsize=(4, 4))\n",
    "\n",
    "x = np.arange(1, div_mean.shape[0]+1)\n",
    "axes.semilogy(x, div_truth[:len(x)], '-k', label='Truth')\n",
    "axes.semilogy(x, div_mean, '-b', label='Emulator')\n",
    "axes.fill_between(x, div_mean-div_std, div_mean+div_std, color='b', alpha=0.1)\n",
    "axes.set_title('$ \\langle |\\\\nabla \\cdot u |\\\\rangle$')\n",
    "axes.set_xlabel('$\\Delta t$')\n",
    "axes.ticklabel_format(axis='x', style='sci', scilimits=(0, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Periods of Extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis.metrics import empirical_return_period, ensemble_return_period_amplitude\n",
    "from analysis.plot_config import params\n",
    "\n",
    "# Reshape truth to mimic ensemble\n",
    "u_max_truth = np.reshape(u_max_truth, shape=(len(run_nums), -1))\n",
    "u_min_truth = np.reshape(u_min_truth, shape=(len(run_nums), -1))\n",
    "v_max_truth = np.reshape(v_max_truth, shape=(len(run_nums), -1))\n",
    "v_min_truth = np.reshape(v_min_truth, shape=(len(run_nums), -1))\n",
    "omega_max_truth = np.reshape(omega_max_truth, shape=(len(run_nums), -1))\n",
    "omega_min_truth = np.reshape(omega_min_truth, shape=(len(run_nums), -1))\n",
    "\n",
    "confidence_level_type = 'percentile'\n",
    "confidence_level = 25\n",
    "\n",
    "markersize = 1\n",
    "bin_num = 100\n",
    "dt_data = 0.02\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8, 10), layout='constrained')\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "data_u = (u_min_truth, u_min_train, u_min, u_max_truth, u_max_train, u_max)\n",
    "data_v = (v_min_truth, v_min_train, v_min, v_max_truth, v_max_train, v_max)\n",
    "data_omega = (omega_min_truth, omega_min_train, omega_min, omega_max_truth, omega_max_train, omega_max)\n",
    "data_labels_min = [r'$u_{min}/\\sigma_u$', r'$v_{min}/\\sigma_v$', r'$\\omega_{min}/\\sigma_{\\omega}$']\n",
    "data_labels_max = [r'$u_{max}/\\sigma_u$', r'$v_{max}/\\sigma_v$', r'$\\omega_{max}/\\sigma_{\\omega}$']\n",
    "\n",
    "for i, data_i in enumerate([data_u, data_v, data_omega]):\n",
    "\n",
    "    data_min_truth, data_min_train, data_min, data_max_truth, data_max_train, data_max = data_i\n",
    "\n",
    "    ### min\n",
    "\n",
    "    #Truth\n",
    "    data_amplitude_mean, data_amplitude_min, data_amplitude_max, return_periods = ensemble_return_period_amplitude(\n",
    "        np.asarray(np.abs(data_min_truth)), dt=dt_data, bins_num=bin_num, confidence_level_type=confidence_level_type, confidence_level=confidence_level)\n",
    "    axes[i, 0].semilogy(-data_amplitude_mean, return_periods, 'ok', label='Truth', markersize=markersize)\n",
    "    axes[i, 0].fill_betweenx(return_periods, -data_amplitude_max, -data_amplitude_min, color='k', alpha=0.2)\n",
    "\n",
    "    # Train\n",
    "    return_period, data_amplitude = empirical_return_period(np.abs(data_min_train), dt=dt_data)\n",
    "    axes[i, 0].semilogy(-data_amplitude, return_period, 'or', label='Train', markersize=markersize)\n",
    "\n",
    "    # Emulator\n",
    "    data_amplitude_mean, data_amplitude_min, data_amplitude_max, return_periods = ensemble_return_period_amplitude(\n",
    "        np.asarray(np.abs(data_min)), dt=dt_data, bins_num=bin_num, confidence_level_type=confidence_level_type, confidence_level=confidence_level)\n",
    "    axes[i, 0].semilogy(-data_amplitude_mean, return_periods, 'ob', label='Emulator', markersize=markersize)\n",
    "    axes[i, 0].fill_betweenx(return_periods, -data_amplitude_max, -data_amplitude_min, color='b', alpha=0.2)\n",
    "\n",
    "\n",
    "    axes[i, 0].set_xlabel(data_labels_min[i])\n",
    "    axes[i, 0].set_ylabel('Return Period')\n",
    "\n",
    "    ### Omega max\n",
    "\n",
    "    # Truth\n",
    "    data_amplitude_mean, data_amplitude_min, data_amplitude_max, return_periods = ensemble_return_period_amplitude(\n",
    "        np.asarray(np.abs(data_max_truth)), dt=dt_data, bins_num=bin_num, confidence_level_type=confidence_level_type, confidence_level=confidence_level)\n",
    "    axes[i, 1].semilogy(data_amplitude_mean, return_periods, 'ok', label='Truth', markersize=markersize)\n",
    "    axes[i, 1].fill_betweenx(return_periods, data_amplitude_max, data_amplitude_min, color='k', alpha=0.2)\n",
    "\n",
    "    # Train\n",
    "    return_period, data_amplitude = empirical_return_period(np.abs(data_max_train), dt=dt_data)\n",
    "    axes[i, 1].semilogy(data_amplitude, return_period, 'or', label='Train', markersize=markersize)\n",
    "\n",
    "    # Emulator\n",
    "    data_amplitude_mean, data_amplitude_min, data_amplitude_max, return_periods = ensemble_return_period_amplitude(\n",
    "        np.asarray(np.abs(data_max)), dt=dt_data, bins_num=bin_num, confidence_level_type=confidence_level_type, confidence_level=confidence_level)\n",
    "    axes[i, 1].semilogy(data_amplitude_mean, return_periods, 'ob', label='Emulator', markersize=markersize)\n",
    "    axes[i, 1].fill_betweenx(return_periods, data_amplitude_max, data_amplitude_min, color='b', alpha=0.2)\n",
    "\n",
    "    axes[i, 1].set_xlabel(data_labels_max[i])\n",
    "\n",
    "    #for count in range(omega_max_emulator_normalized.shape[0]):\n",
    "    #    return_period, data_amplitude = empirical_return_period(np.abs(omega_max_emulator_normalized[count,#:]), dt=dt_data)\n",
    "    #    axes[1].semilogy(data_amplitude, return_period, 'og', label='Train', markersize=markersize)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylim([1e-2, 1e4])\n",
    "# axes[0].set_xlim([-4.5, -1.2])\n",
    "# axes[1].set_xlim([1.2, 4.5])\n",
    "# plt.suptitle('97.5% CI error calculated with 200 ensembles of 2500 snapshots')\n",
    "axes[2, 1].legend(loc='upper left', frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
