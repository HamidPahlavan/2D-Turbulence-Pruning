### base config ####
BASE: &BASE
    data_dir: '/pscratch/sd/d/dpp94/2DTurbData/results/Re5000_fkx4fky4_r0.1_b20.0/NoSGS/NX256/dt0.0002_IC1/'

    exp_dir: '/pscratch/sd/d/dpp94/SSL-2DTurb/'

    init_seed: 0
    
    log_to_screen: !!bool True
    log_to_wandb: !!bool False #True
    wandb_table_logging_interval: 10
    project: 'SSL-2DTurb'
    group: 'Dhruvit-base-emulator'
    name: '0000'
    diagnostic_logs: !!bool True

    fresh_start: True
    early_stopping: !!bool False

    save_checkpoint: !!bool True
    ckpt_epoch_list: [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500]

    train_file_range: [200000, 220000]
    valid_file_range: [310000, 312000]
    batch_size: 32 
    target_step: 3
    num_workers: 8
    pin_memory: !!bool True

    gpu: !!bool True
    lr: 5e-4
    scheduler: 'ReduceLROnPlateau'
    warmup: !!bool True
    warmup_startfactor: 0.001 
    warmup_totaliters: 3
    weight_decay: 1e-7 # 1e-7   # 1e-7 for video; 1e-6 for image
    max_epochs: 500
    checkpointing: !!bool False #True

    train_tendencies: !!bool False #True

    img_size: 256
    patch_size: 4
    num_frames: 2
    tubelet_size: 2
    in_chans: 2
    encoder_embed_dim: 192 # 96
    encoder_depth: 4 
    encoder_num_heads: 4 
    decoder_embed_dim: 96 
    decoder_depth: 4 
    decoder_num_heads: 4 
    mlp_ratio: 4.
    num_out_frames: 1
    patch_recovery: "subpixel_conv"  #["linear", "conv", "subpixel_conv"]

    mae_finetune: False



MAE_PRETRAIN: &MAE_PRETRAIN
    <<: *BASE

    init_seed: 0

    log_to_screen: !!bool True
    log_to_wandb: !!bool False #True
    wandb_table_logging_interval: 10
    project: 'SSL-2DTurb'
    group: 'Dhruvit-mae-pretrain'
    name: '0000'
    diagnostic_logs: !!bool True

    ckpt_epoch_list: []

    target_step: 0
    target_step_hist: 3

    train_file_range: [200000, 220000]
    valid_file_range: [310000, 312000]

    num_frames: 2
    tubelet_size: 2
    num_out_frames: 2  

    mask_ratio: 0.5



MAE_FINETUNE: &MAE_FINETUNE
    <<: *MAE_PRETRAIN

    init_seed: 0 

    log_to_screen: !!bool True
    log_to_wandb: !!bool True
    wandb_table_logging_interval: 10
    project: 'SSL-2DTurb'
    group: 'Dhruvit-mae-finetune'
    name: 'testing_diagnostics'
    diagnostic_logs: !!bool True

    ckpt_epoch_list: [1, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500]

    target_step: 3
    target_step_hist: 3

    train_file_range: [200000, 220000]
    valid_file_range: [310000, 312000]
   
    lr: 5e-4
    scheduler: 'ReduceLROnPlateau'
    warmup: !!bool False
    max_epochs: 500

    num_out_frames: 1

    mae_finetune: True
    mae_finetune_fp: '/pscratch/sd/d/dpp94/SSL-2DTurb/MAE_PRETRAIN/0002/training_checkpoints/best_ckpt.tar'
    freeze_layers: [] #['encoder', 'patch_embed']   
    drop_layers: [] #['decoder', 'patchrecovery']



SMAE_PRETRAIN: &SMAE_PRETRAIN
    <<: *BASE

    init_seed: 0 

    log_to_screen: !!bool True
    log_to_wandb: !!bool True
    wandb_table_logging_interval: 20
    project: 'SSL-2DTurb'
    group: 'Dhruvit-smae-pretrain'
    name: '0000'
    diagnostic_logs: !!bool True

    ckpt_epoch_list: []

    target_step: 0
    target_step_hist: 3

    train_file_range: [200000, 220000]
    valid_file_range: [310000, 312000]

    num_frames: 2
    tubelet_size: 2
    num_out_frames: 2  

    preprocess: 'Fourier'
    cutoff_low: 0.01
    cutoff_high: 0.05
    filter_shuffle: False
    filter_type: 'lowpass'
    window_type: 'gaussian'
    tukey_alpha: 1
    use_spectral_weights: False
    spectrally_weigh_input: False
    spectrally_weigh_output: False



SMAE_FINETUNE: &SMAE_FINETUNE
    <<: *SMAE_PRETRAIN

    log_to_screen: !!bool True
    log_to_wandb: !!bool True
    wandb_table_logging_interval: 20
    project: 'SSL-2DTurb'
    group: 'Dhruvit-smae-finetune'
    name: '0000_v1_full'
    diagnostic_logs: !!bool True

    ckpt_epoch_list: [1, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375, 400, 425, 450, 475, 500]

    target_step: 3
    target_step_hist: 3

    train_file_range: [200000, 220000]
    valid_file_range: [310000, 312000]

    lr: 5e-4
    scheduler: 'ReduceLROnPlateau'
    warmup: !!bool False
    max_epochs: 500
    
    num_frames: 2
    tubelet_size: 2
    num_out_frames: 1

    smae_finetune: True
    smae_finetune_fp: '/pscratch/sd/d/dpp94/SSL-2DTurb/SMAE_PRETRAIN/0000_v1/training_checkpoints/best_ckpt.tar'
    freeze_layers: [] #['encoder', 'patch_embed']   
    drop_layers: [] #['decoder', 'patchrecovery']